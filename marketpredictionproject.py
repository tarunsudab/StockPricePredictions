# -*- coding: utf-8 -*-
"""MarketPredictionProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yJEctyjqEDYwjjZRd6o6Me0AxckXn2ly
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix
from sklearn.inspection import permutation_importance

"""# Data Collection"""

stocks = {}

# Prediction
stocks['AAPL'] = pd.read_csv("AAPL.csv")

# Peer Context
stocks['AMZN'] = pd.read_csv("AMZN.csv")
stocks['MSFT'] = pd.read_csv("MSFT.csv")

# Market
stocks['SPY'] = pd.read_csv("SPY.csv")

# Tech Context
stocks['XLK'] = pd.read_csv("XLK.csv")
stocks['QQQ'] = pd.read_csv("QQQ.csv")

# Rates Proxy
stocks['TLT'] = pd.read_csv("TLT.csv")
stocks['IEF'] = pd.read_csv("IEF.csv")

for s in stocks:
  stock = stocks[s]

  # Replace $ and other special characters to convert to decimal
  stock = stock.replace({',': '', '\s+': '', '\$': ''}, regex=True)

  # Convert date to datetime
  stock['Date'] = pd.to_datetime(stock['Date'], errors='coerce')

  # Convert columns to decimals
  for col in stock.columns:
    if col != 'Date':
      stock[col] = pd.to_numeric(stock[col], errors='coerce')

  # Sort the values in ascending for later on
  stock.sort_values('Date', inplace=True, ascending=True)
  stock.set_index('Date', inplace=True)
  stocks[s] = stock
  print(stock.head())

# Put all the values for all the stocks in 1 dataframe for comparison
close_prices = pd.DataFrame()

for stock, data in stocks.items():
  close_prices[stock] = data['Close/Last']

close_prices.head()

# Calculate percent change for each stock

change = close_prices.pct_change().dropna()
change.columns = [f"{s}_change" for s in change.columns]

change.head()

target_stock = 'AAPL'
target_col = f"{target_stock}_change"

# Find if the next day change is positive or negative
next_day_change = change[target_col].shift(-1)
#print(next_day_change)

# Convert the change into binary where 0 means negative change and 1 means positive change
target = (next_day_change > 0).astype(int)
print(target)

# Inputted the target into a new DF so that we can split it into training and test data
model_df = change.copy()
model_df[f"{target_stock}_target"] = target
model_df = model_df.dropna()
model_df.head()

# Data set split for Log Reg

# Split into training and test sets
split_idx = int(len(model_df) * 0.8)

# Getting the X and Y
X = model_df.drop(f"{target_stock}_target", axis = 1)
Y = model_df[f"{target_stock}_target"]

# Need to use iloc since we need to split based on the number of rows and not the actual values
X_train = X.iloc[:split_idx]
X_test = X.iloc[split_idx:]

Y_train = Y.iloc[:split_idx]
Y_test = Y.iloc[split_idx:]

#X_train = train.drop(f"{target_stock}_target", axis = 1)
#Y_train = train[f"{target_stock}_target"]

#X_test = test.drop(f"{target_stock}_target", axis = 1)
#Y_test = test[f"{target_stock}_target"]

# Scaling by transforming the values (NEED TO RESEARCH FURTHER)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

pd.DataFrame(X_train_scaled, columns=X_train.columns).head()

# Logistic Regression
model = LogisticRegression(max_iter=5000, class_weight="balanced")
model.fit(X_train_scaled, Y_train)

predictions = model.predict(X_test_scaled)

print("Logistic Regression Acuracy: ", accuracy_score(Y_test, predictions))
print("Logistic Regression Classification Report: \n", classification_report(Y_test, predictions))

# Data set split for Random Forest

# Split into training, validation, and test sets
train_end = int(len(model_df) * 0.6)
val_end = int(len(model_df) * 0.8)

# Getting the X (freatures) and Y (target)
X = model_df.drop(f"{target_stock}_target", axis = 1)
Y = model_df[f"{target_stock}_target"]

# Need to use iloc since we need to split based on the number of rows and not the actual values
X_train = X.iloc[:train_end]
Y_train = Y.iloc[:train_end]

X_val = X.iloc[train_end:val_end]
Y_val = Y.iloc[train_end:val_end]

X_test = X.iloc[val_end:]
Y_test = Y.iloc[val_end:]

print(len(X_train), len(X_val), len(X_test))
print("Train dates:", X_train.index.min(), "→", X_train.index.max())
print("Val dates:",   X_val.index.min(),   "→", X_val.index.max())
print("Test dates:",  X_test.index.min(),  "→", X_test.index.max())

# Random Forest Creation
rf = RandomForestClassifier(n_estimators=300, max_depth=8, random_state=42, n_jobs=-1)
rf.fit(X_train, Y_train)

val_probs = rf.predict_proba(X_val)[:, 1]

# Trying the different thresholds
thresholds = [0.50, 0.55, 0.60, 0.65]
results = []

for threshold in thresholds:
  val_pos = (val_probs > threshold).astype(int)
  trades = val_pos.sum()
  trade_rate = trades / len(val_pos)

  if trades > 0:
    win_rate = ((val_pos == 1) & (Y_val.values == 1)).sum() / trades
  else:
    win_rate = np.nan

  results.append((threshold, trade_rate, win_rate))
  print(f"thr={threshold:.2f} | trade_rate={trade_rate:.3f} | win_rate={win_rate:.3f}")

# Using the best threshold
best_t = 0.55

test_probs = rf.predict_proba(X_test)[:, 1]
test_pos = (test_probs > best_t).astype(int)

trades = test_pos.sum()
trade_rate = trades / len(test_pos)

if trades > 0:
  win_rate = ((test_pos == 1) & (Y_test.values == 1)).sum() / trades
else:
  win_rate = np.nan

print(f"TEST | thr={best_t:.2f} | trade_rate={trade_rate:.3f} | win_rate={win_rate:.3f}")

test_preds = (test_probs > best_t).astype(int)

print("Random Forest Accuracy: ", accuracy_score(Y_test, test_preds))
print("Random Forest Classfication Report: \n", classification_report(Y_test, test_preds))
print("Random Forest Confusion Matrix: \n", confusion_matrix(Y_test, test_preds))

Y_test.value_counts(normalize=True)

# Checking importances of the features

# Permutation importance means if I were to destroy this feature's
# information, how much does the model performance change?
perm = permutation_importance(
    rf, X_val, Y_val,
    n_repeats = 10,
    random_state = 42,
    n_jobs = -1
)

# Basically means across the trees in the forest,
# these are the most important features that are being commonly used

#importances = rf.feature_importances_
feat_imp = pd.DataFrame({"feature" : X_val.columns,
                         "importance" : perm.importances_mean}).sort_values("importance", ascending=False)
feat_imp

#feat_imp.head().plot(kind="bar", x="feature", y="importance", figsize=(10,4), legend=False)

"""# NLP Sentiment"""

!pip install -q finnhub-python
!pip install -q transformers torch

import finnhub
import pytz

from datetime import datetime, timedelta
from transformers import pipeline

# Connecting to API
FINNHUB_API_KEY = "d504ushr01qsabpr6db0d504ushr01qsabpr6dbg"
client = finnhub.Client(api_key=FINNHUB_API_KEY)

# Gettings dates from the past year (since free API only gives that)
symbol = "AAPL"
end_date = datetime.now()
start_date = end_date - timedelta(days=365)

# Getting news between the dates above
news = client.company_news(
    symbol,
    _from = start_date.strftime("%Y-%m-%d"),
    to = end_date.strftime("%Y-%m-%d")
)

# Normalizing into a dataframe with the datetime
news_df = pd.DataFrame(news)
news_df = news_df[['datetime', 'headline']]
news_df['datetime'] = pd.to_datetime(news_df['datetime'], unit='s', utc=True)

# Caching so don't pull every time
news_df.to_csv("AAPL_NEWS.csv", index=False)

news_df.head()

# Moving all news articles that come out after hours to the next day
# WOULD LIKE TO REVIEW FURTHER
timezone = pytz.timezone("America/New_York")
news_df['datetime_zone'] = news_df['datetime'].dt.tz_convert(timezone)

market_close_hour = 16

news_df['feature_date'] = news_df['datetime_zone'].dt.date
after_close = news_df['datetime_zone'].dt.hour >= market_close_hour

news_df.loc[after_close, 'feature_date'] = (news_df.loc[after_close, 'datetime_zone'] + pd.Timedelta(days=1)).dt.date

# FinBERT sentiment on headlines

sentiment = pipeline(
    "sentiment-analysis",
    model="ProsusAI/finbert",
    tokenizer="ProsusAI/finbert",
    truncation=True
)

headlines = news_df['headline'].fillna("").astype(str).tolist()

outputs = []
batch_size = 32
for i in range(0, len(headlines), batch_size):
  outputs.extend(sentiment(headlines[i:i+batch_size]))

news_df['label'] = [o['label'] for o in outputs]
news_df['score'] = [o['score'] for o in outputs]

news_df['pos'] = np.where(news_df['label'] == 'positive', news_df['score'], 0.0)
news_df['neg'] = np.where(news_df['label'] == 'negative', news_df['score'], 0.0)
news_df['neu'] = np.where(news_df['label'] == 'neutral', news_df['score'], 0.0)

news_df.head()

# Aggregate in NLP Features

daily_sent = news_df.groupby('feature_date').agg(
    headline_count=('headline', 'count'),
    pos_mean=('pos', 'mean'),
    neg_mean=('neg', 'mean'),
    neu_mean=('neu', 'mean'),
    pos_sum=('pos', 'sum'),
    neg_sum=('neg', 'sum'),
).reset_index()

daily_sent['net_sentiment'] = daily_sent['pos_mean'] - daily_sent['neg_mean']
daily_sent.rename(columns={'feature_date':'Date'}, inplace=True)

daily_sent.head()

# Merging into main DataFrame
model_df_nlp = model_df.copy()

if isinstance(model_df_nlp.index, pd.DatetimeIndex):
  model_df_nlp = model_df_nlp.reset_index()

  date_col = 'Date' if 'Date' in model_df_nlp.columns else model_df_nlp.columns[0]
  model_df_nlp['Date'] = pd.to_datetime(model_df_nlp[date_col]).dt.date
else:
  raise ValueError("model_df_nlp needs to be indexed by dates")

model_df_nlp = model_df_nlp.merge(daily_sent, on='Date', how='left')

# Filling in missing NLP with neutral default
fill_cols = ['headline_count', 'pos_mean', 'neg_mean', 'neu_mean', 'pos_sum', 'neg_sum', 'net_sentiment']
model_df_nlp['headline_count'] = model_df_nlp['headline_count'].fillna(0)
for c in fill_cols[1:]:
  model_df_nlp[c] = model_df_nlp[c].fillna(0.0)

# Indicator Feature
model_df_nlp['has_news'] = (model_df_nlp['headline_count'] > 0).astype(int)

model_df_nlp = model_df_nlp.set_index(date_col)

model_df_nlp.head()

# Splitting up data -- important to only do the last 1 year since that is the NLP information we have

model_df_nlp.index = pd.to_datetime(model_df_nlp.index)
cutoff = pd.Timestamp(end_date - timedelta(days=365))
model_1y = model_df_nlp[model_df_nlp.index >= cutoff].dropna()

# Split into training, validation, and test sets
train_end = int(len(model_1y) * 0.6)
val_end = int(len(model_1y) * 0.8)

# Getting the X (freatures) and Y (target)
X = model_1y.drop(f"{target_stock}_target", axis = 1)
Y = model_1y[f"{target_stock}_target"]

# Need to use iloc since we need to split based on the number of rows and not the actual values
X_train = X.iloc[:train_end]
Y_train = Y.iloc[:train_end]

X_val = X.iloc[train_end:val_end]
Y_val = Y.iloc[train_end:val_end]

X_test = X.iloc[val_end:]
Y_test = Y.iloc[val_end:]

rf_nlp = RandomForestClassifier(n_estimators=400, max_depth=10, random_state=42, n_jobs=-1)
rf_nlp.fit(X_train, Y_train)

rf_nlp_preds = rf_nlp.predict(X_test).astype(int)

print("Random Forest Accuracy: ", accuracy_score(Y_test, rf_nlp_preds))
print("Random Forest Classfication Report: \n", classification_report(Y_test, rf_nlp_preds))
print("Random Forest Confusion Matrix: \n", confusion_matrix(Y_test, rf_nlp_preds))

# Checking thresholds

probs = rf_nlp.predict_proba(X_test)[:, 1]
# print(probs[:10])

# testing from 0.45 - 0.70 to find thresholds
thresholds = np.arange(0.45, 0.70, 0.02)

rows = []

for t in thresholds:
  rf_nlp_preds_t = (probs >= t).astype(int)

  rows.append({
      "threshold":t,
      "accuracy":accuracy_score(Y_test, rf_nlp_preds_t),
      "precision_up":precision_score(Y_test, rf_nlp_preds_t, zero_division=0),
      "recall_up":recall_score(Y_test, rf_nlp_preds_t),
      "trades":rf_nlp_preds_t.sum()
  })

results = pd.DataFrame(rows)
results

# 0.47 becomes the threshold

perm = permutation_importance(
    rf_nlp, X_val, Y_val,
    n_repeats = 20,
    random_state = 42,
    n_jobs=-1
)

perm_df = pd.DataFrame({
    "feature" : X_val.columns,
    "importance" : perm.importances_mean,
    "std" : perm.importances_std
}).sort_values("importance", ascending=False)

perm_df

# Predicting tomorrow's price

X_today = model_df_nlp.drop(columns=[f"{target_stock}_target"]).iloc[-1:]
prob_up = rf_nlp.predict_proba(X_today)[0,1]
print("Initial probability to go up: ", prob_up)

threshold = 0.47
prediction = int(prob_up >= threshold)

if prediction == 1:
  print("The model predicts AAPL will go UP tomorrow.")
else:
  print("The model predicts AAPL will go DOWN tomorrow.")

model_df_nlp

# Getting the old DF to add the close prices for AAPL (target)
AAPL = stocks['AAPL']
AAPL_close = AAPL[['Close/Last']].copy()
AAPL_close = AAPL_close.rename(columns={'Close/Last': 'AAPL_close'})

model_df_nlp.head()

# Merge close prices to the main DF
model_df_nlp = model_df_nlp.merge(
    AAPL_close,
    left_index=True,
    right_index=True,
    how='left'
)

print(model_df_nlp[['AAPL_close', 'AAPL_change']].head())
print(model_df_nlp[['AAPL_close', 'AAPL_change']].tail())

# Predicting next week's price

HORIZON = 5

model_df_nlp['AAPL_close_future'] = model_df_nlp['AAPL_close'].shift(-HORIZON)

model_df_nlp['target_5d'] = (
    model_df_nlp['AAPL_close_future'] > model_df_nlp['AAPL_close']
).astype(int)

model_df_nlp_5d = model_df_nlp.dropna(subset=['target_5d'])

model_df_nlp_5d

exclude_cols = [
    "target",
    "target_5d",
    "AAPL_close",
    "AAPL_close_future",
    "AAPL_target"
]

X = model_df_nlp_5d.drop(columns=exclude_cols, errors="ignore")
Y = model_df_nlp_5d["target_5d"]

# Split into training, validation, and test sets
train_end = int(len(model_df_nlp_5d) * 0.6)
val_end = int(len(model_df_nlp_5d) * 0.8)

# Need to use iloc since we need to split based on the number of rows and not the actual values
X_train = X.iloc[:train_end]
Y_train = Y.iloc[:train_end]

X_val = X.iloc[train_end:val_end]
Y_val = Y.iloc[train_end:val_end]

X_test = X.iloc[val_end:]
Y_test = Y.iloc[val_end:]

rf_nlp_5d = RandomForestClassifier(n_estimators=400, max_depth=10, random_state=42, n_jobs=-1)
rf_nlp_5d.fit(X_train, Y_train)

rf_nlp_preds_5d = rf_nlp_5d.predict(X_test)

print("Random Forest Accuracy: ", accuracy_score(Y_test, rf_nlp_preds_5d))
print("Random Forest Classfication Report: \n", classification_report(Y_test, rf_nlp_preds_5d))
print("Random Forest Confusion Matrix: \n", confusion_matrix(Y_test, rf_nlp_preds_5d))

# Checking thresholds

probs_5d = rf_nlp_5d.predict_proba(X_test)[:, 1]

# testing from 0.45 - 0.70 to find thresholds
thresholds = np.arange(0.45, 0.70, 0.02)

rows = []

for t in thresholds:
  rf_nlp_5d_preds_t = (probs_5d >= t).astype(int)

  rows.append({
      "threshold":t,
      "accuracy":accuracy_score(Y_test, rf_nlp_5d_preds_t),
      "precision_up":precision_score(Y_test, rf_nlp_5d_preds_t, zero_division=0),
      "recall_up":recall_score(Y_test, rf_nlp_5d_preds_t),
      "trades":rf_nlp_5d_preds_t.sum()
  })

results_5d = pd.DataFrame(rows)
results_5d

# 0.55 becomes the threshold

# Predicting next week's price

exclude_cols_5d = [
    "target",
    "target_5d",
    "AAPL_close",
    "AAPL_close_future",
    "AAPL_target"
]

X_next_week = model_df_nlp_5d.drop(columns=exclude_cols_5d, errors="ignore").iloc[-1:]
prob_up_5d = rf_nlp.predict_proba(X_next_week)[0,1]
print("Initial probability to go up: ", prob_up_5d)

threshold = 0.55
prediction = int(prob_up >= threshold)

if prediction == 1:
  print("The model predicts AAPL will go UP next week.")
else:
  print("The model predicts AAPL will go DOWN next week.")

H = 5
r5 = model_df_nlp["AAPL_close"].pct_change(H).dropna()

mu_up = r5[r5 > 0].mean()
mu_dn = r5[r5 <= 0].mean()

p = 0.7488837198380227
expected_r = p * mu_up + (1 - p) * mu_dn

current_price = model_df_nlp["AAPL_close"].iloc[-1]
expected_price = current_price * (1 + expected_r)

print("Current:", current_price)
print("Expected 5d return:", expected_r)
print("Expected price in 5 trading days:", expected_price)

# Graphing the results

HORIZON=5
r5 = model_df_nlp["AAPL_close"].pct_change(HORIZON).dropna()

plt.figure(figsize=(8,5))
plt.hist(r5, bins=50)
plt.axvline(expected_r, color='red')
plt.title("Distribution of AAPL 5-Day Returns")
plt.xlabel("5-Day Return")
plt.ylabel("Frequency")
plt.show()

# Backtesting the model
bt_df = model_df_nlp_5d.copy()

# Excluding certain columns
X_all = bt_df.loc[:, rf_nlp_5d.feature_names_in_]

# Getting weekly probablities for every date
bt_df['prob_up_5d'] = rf_nlp_5d.predict_proba(X_all)[:, 1]

# Apply the threshold and decision rule
THRESHOLD = 0.55
model_df_nlp_5d['signal'] = (model_df_nlp_5d['prob_up_5d'] >= THRESHOLD).astype(int)

# Computing the realized 5-day forward return -- understand code a little more
HORIZON = 5
bt_df['return_5d'] = bt_df['AAPL_close'].pct_change(HORIZON)

# Drop rows with no future data and keep only every 5 weeks to avoid overlap
bt_df = bt_df.dropna(subset=['return_5d'])
bt_df['week_id'] = np.arange(len(bt_df)) // 5
bt_weekly = bt_df.groupby('week_id').last()

# Strategy vs. Buy-and-Hold returns
# Strategy selectively takes risk
# Buy-and-Hold always takes risk
bt_weekly['strategy_return'] = bt_weekly['signal'] * bt_weekly['return_5d']
bt_weekly['bh_return'] = bt_weekly['return_5d']

# Cumulative performance
bt_weekly['strategy_cum_return'] = (1 + bt_weekly['strategy_return']).cumprod()
bt_weekly['bh_cum_return'] = (1 + bt_weekly['bh_return']).cumprod()

plt.figure(figsize=(9,5))
plt.plot(bt_weekly.index, bt_weekly['strategy_cum_return'], label='ML Weekly Strategy')
plt.plot(bt_weekly.index, bt_weekly['bh_cum_return'], linestyle='--', label='Buy & Hold')
plt.title("AAPL Weekly Backtest (5-Day Horizon)")
plt.ylabel("Cumulative Return")
plt.legend()
plt.show()